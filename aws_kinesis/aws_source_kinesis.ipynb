{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is an example of how to write a Python script to send data to your Kinesis stream.\n",
    "# This scipt is run in the on-premises environment where the data is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptography.fernet import Fernet # fernet is a symmetric encryption algorithm that uses the same key for both encryption and decryption\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Generate and print a key. This should be done once and securely stored.\n",
    "# key = Fernet.generate_key()\n",
    "# print(f\"Save this key: {key.decode()}\")\n",
    "\n",
    "# Replace with your stored key\n",
    "key = b'your-encryption-key-here'  # This should be a securely stored key\n",
    "cipher_suite = Fernet(key)  # Create a cipher suite with the key which will be used to encrypt and decrypt data\n",
    "\n",
    "# Initialize the Kinesis client\n",
    "kinesis_client = boto3.client('kinesis', region_name='your-region')\n",
    "\n",
    "# Stream name\n",
    "stream_name = 'your-stream-name'\n",
    "\n",
    "# Path to the folder containing .log files\n",
    "folder_path = 'path/to/your/folder'\n",
    "\n",
    "def get_data_from_file(file_path):\n",
    "    \"\"\"Read JSON data from a .log file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file) # load is used to convert a JSON string into a Python object \n",
    "                               # This is used to read the JSON data from the file and convert it into a Python object\n",
    "\n",
    "def encrypt_data(data):\n",
    "    \"\"\"Encrypt JSON data using Fernet.\"\"\"\n",
    "    json_data = json.dumps(data).encode('utf-8')  # Convert data to JSON string and encode it to bytes for encryption\n",
    "    encrypted_data = cipher_suite.encrypt(json_data)\n",
    "    return encrypted_data\n",
    "\n",
    "def send_to_kinesis(data):\n",
    "    \"\"\"Encrypt and send data to Kinesis.\"\"\"\n",
    "    encrypted_data = encrypt_data(data) # Encrypt the data before sending it to Kinesis\n",
    "    response = kinesis_client.put_record(\n",
    "        StreamName=stream_name,\n",
    "        Data=encrypted_data,\n",
    "        PartitionKey='partitionKey'\n",
    "    )\n",
    "    print(f\"Sent encrypted data: {encrypted_data} to Kinesis with response: {response}\")\n",
    "\n",
    "def process_logs():\n",
    "    \"\"\"Process .log files in the specified folder.\"\"\"\n",
    "    for filename in os.listdir(folder_path): # Here we are listing all the files in the folder \n",
    "        if filename.endswith('.log'): # Check if the file is a .log file \n",
    "            file_path = os.path.join(folder_path, filename) # Get the full path of the file\n",
    "            try:\n",
    "                data = get_data_from_file(file_path)\n",
    "                send_to_kinesis(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "# Simulate a continuous stream of data\n",
    "while True:\n",
    "    process_logs()\n",
    "    time.sleep(60)  # Check the folder every minute, adjust as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Kinesis Agent configuration is typically stored in /etc/aws-kinesis/agent.json. \n",
    "# You need to edit this file to specify which log files to monitor and where to send the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"cloudwatch.emitMetrics\": true,\n",
    "    \"firehose.endpoint\": \"firehose.us-west-2.amazonaws.com\",\n",
    "    \"kinesis.endpoint\": \"kinesis.us-west-2.amazonaws.com\",\n",
    "    \"kinesis.streamName\": \"your-stream-name\",\n",
    "    \"kinesis.roleArn\": \"arn:aws:iam::your-account-id:role/your-kinesis-role\",\n",
    "    \"logs\": [\n",
    "        {\n",
    "            \"filePattern\": \"/path/to/your/folder/*.log\",\n",
    "            # logGroupName: The name of the CloudWatch Logs group (if used with CloudWatch).\n",
    "            \"logGroupName\": \"your-log-group\", # The log group where the logs will be stored.\n",
    "            # logStreamName: The name of the CloudWatch Logs stream (if used with CloudWatch).\n",
    "            \"logStreamName\": \"{instance_id}/your-log-stream\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# sudo service amazon-kinesis-agent start ---> To start the Kinesis Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure Lambda to process the data from the Kinesis stream and store it in an S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "from cryptography.fernet import Fernet\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Retrieve the Fernet key from environment variables\n",
    "fernet_key = os.environ.get('FERNET_KEY')\n",
    "cipher_suite = Fernet(fernet_key.encode()) # we are using encode() to convert the key to bytes before passing it to Fernet\n",
    "\n",
    "def lambda_handler(event, context):# event is the input data that triggers the Lambda function.\n",
    "                                    # context provides information about the invocation, function, and execution environment.\n",
    "    # Iterate through each record in the batch\n",
    "    for record in event['Records']:\n",
    "        # Decode the record's data (base64 encoded)\n",
    "        encrypted_data = base64.b64decode(record['kinesis']['data'])\n",
    "        \n",
    "        # Decrypt the data using the Fernet key\n",
    "        decrypted_data = cipher_suite.decrypt(encrypted_data).decode('utf-8')\n",
    "        payload = json.loads(decrypted_data) # Convert the decrypted data to a python object\n",
    "        \n",
    "        # Get the current time for partitioning\n",
    "        now = datetime.utcnow()\n",
    "        year = now.strftime('%Y')\n",
    "        month = now.strftime('%m')\n",
    "        day = now.strftime('%d')\n",
    "        hour = now.strftime('%H')\n",
    "        \n",
    "        # Define the S3 bucket and object key\n",
    "        bucket_name = 'your-s3-bucket-name'\n",
    "        object_key = f\"{year}/{month}/{day}/{hour}/data-{context.aws_request_id}.json\"\n",
    "        \n",
    "        # Save the decrypted data to S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=object_key,\n",
    "            Body=json.dumps(payload), # Convert the payload to a JSON string before saving\n",
    "            ContentType='application/json' # Set the content type to JSON for easy reading in S3 console or other tools\n",
    "                                           # This content type is used to indicate the type of data in the object\n",
    "                                           # In this case, it's JSON data\n",
    "                                           # This is useful for tools that read the object to know how to interpret the data \n",
    "                                           # It can be used as a hint for the type of data in the object\n",
    "        )\n",
    "        \n",
    "        print(f\"Saved record to S3: s3://{bucket_name}/{object_key}\")\n",
    "    \n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('Processed records successfully.')# Return a response indicating successful processing\n",
    "        # we are using json.dumps to convert the response into a JSON string before returning it\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also map the Lambda function to the Kinesis stream so that it automatically processes the data as it arrives.\n",
    "\n",
    "aws lambda create-event-source-mapping \n",
    "--function-name MyLambdaFunction \n",
    "--batch-size 100 \n",
    "--event-source-arn arn:aws:kinesis:your-region:your-account-id:stream/your-stream-name --starting-position TRIM_HORIZON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
