{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws kinesis create-stream --stream-name my-kinesis-stream --shard-count 3\n",
    "aws kinesis list-streams\n",
    "aws kinesis describe-stream --stream-name my-kinesis-stream\n",
    "aws kinesis update-shard-count --stream-name my-kinesis-stream --target-shard-count 5 --scaling-type UNIFORM_SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws cloudwatch put-metric-alarm \\\n",
    "    --alarm-name KinesisHighRecordCount \\ # Name of the alarm \n",
    "    --metric-name IncomingRecords \\ # Name of the metric\n",
    "    --namespace AWS/Kinesis \\ # Namespace of the metric \n",
    "    --statistic Sum \\ # Statistic to apply to the metric \n",
    "    --period 300 \\ # Period of the metric \n",
    "    --threshold 10000 \\ # Threshold for the alarm \n",
    "    --comparison-operator GreaterThanThreshold \\ # Comparison operator to use\n",
    "    --dimensions Name=StreamName,Value=my-kinesis-stream \\ # Dimensions to apply to the metric\n",
    "    --evaluation-periods 1 \\ # Number of periods to evaluate the metric\n",
    "    --alarm-actions arn:aws:sns:region:account-id:my-sns-topic \\ # SNS topic to send notifications to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws cloudwatch get-metric-data \\\n",
    "    --metric-data-queries '[{\"Id\":\"m1\",\"MetricStat\":{\"Metric\":{\"Namespace\":\"AWS/Kinesis\",\"MetricName\":\"IncomingRecords\",\"Dimensions\":[{\"Name\":\"StreamName\",\"Value\":\"my-kinesis-stream\"}]},\"Period\":300,\"Stat\":\"Sum\"}}]' \\\n",
    "    --start-time 2024-08-01T00:00:00Z \\\n",
    "    --end-time 2024-08-02T00:00:00Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws firehose create-delivery-stream \\\n",
    "    --delivery-stream-name my-firehose-stream \\\n",
    "    --s3-destination-configuration RoleARN=arn:aws:iam::123456789012:role/firehose-role,BucketARN=arn:aws:s3:::my-bucket\n",
    "\n",
    "aws firehose list-delivery-streams\n",
    "aws firehose describe-delivery-stream --delivery-stream-name my-firehose-stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Configuring Buffer and Batch Size in Kinesis Firehose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws firehose update-destination \\\n",
    "    --delivery-stream-name my-firehose-stream \\\n",
    "    --current-delivery-stream-version-id 1 \\\n",
    "    --s3-destination-update '{\"BufferingHints\": {\"IntervalInSeconds\": 300, \"SizeInMBs\": 5}}'\n",
    "\n",
    "    # This command will update the buffer interval to 300 seconds and the buffer size to 5 MB. \n",
    "    # The buffer interval is the amount of time that Firehose waits before delivering data to the destination, \n",
    "    # we can optimize the buffer size and buffer interval to reduce the number of PUT requests to S3. \n",
    "    # no of PUT requests = (buffer size / buffer interval) * no of records per second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws lambda create-function \\\n",
    "    --function-name my-lambda-function \\\n",
    "    --runtime python3.8 \\\n",
    "    --role arn:aws:iam::123456789012:role/lambda-role \\\n",
    "    --handler lambda_function.lambda_handler \\\n",
    "    --zip-file fileb://function.zip \\\n",
    "    --environment Variables={FERNET_KEY=your-fernet-key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Retrieve the key from environment variables\n",
    "key = bytes(os.environ['FERNET_KEY'], 'utf-8')\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'your-s3-bucket'\n",
    "\n",
    "def validate_data(data):\n",
    "    # Check if required fields are present\n",
    "    if 'id' not in data or 'timestamp' not in data:\n",
    "        raise ValueError(\"Invalid data format\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        payload = base64.b64decode(record['kinesis']['data'])\n",
    "        decrypted_data = cipher_suite.decrypt(payload).decode('utf-8')\n",
    "        data = json.loads(decrypted_data)\n",
    "\n",
    "        # Validate data\n",
    "        validate_data(data)\n",
    "\n",
    "        # Process data and save to S3\n",
    "        s3_key = f\"{data['year']}/{data['month']}/{data['day']}/{data['hour']}/{data['id']}.json\"\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=s3_key,\n",
    "            Body=json.dumps(data)\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('Data processed successfully.')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws lambda add-permission \\\n",
    "    --function-name my-lambda-function \\\n",
    "    --principal kinesis.amazonaws.com \\\n",
    "    --statement-id some-unique-id \\\n",
    "    --action lambda:InvokeFunction \\\n",
    "    --source-arn arn:aws:kinesis:region:account-id:stream/my-kinesis-stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws lambda create-event-source-mapping \\\n",
    "    --function-name my-lambda-function \\\n",
    "    --event-source-arn arn:aws:kinesis:region:account-id:stream/my-kinesis-stream \\\n",
    "    --starting-position TRIM_HORIZON \\\n",
    "    --batch-size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws kinesis start-stream-encryption \\\n",
    "    --stream-name my-kinesis-stream \\\n",
    "    --encryption-type KMS \\\n",
    "    --key-id alias/my-kms-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enable S3 Server-Side Encryption:\n",
    "\n",
    "aws s3api put-bucket-encryption \\\n",
    "    --bucket your-s3-bucket \\\n",
    "    --server-side-encryption-configuration '{\"Rules\":[{\"ApplyServerSideEncryptionByDefault\":{\"SSEAlgorithm\":\"AES256\"}}]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws lambda update-function-configuration \\\n",
    "    --function-name my-lambda-function \\\n",
    "    --dead-letter-config TargetArn=arn:aws:sqs:region:account-id:my-dlq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws glue create-crawler \\\n",
    "    --name my-glue-crawler \\\n",
    "    --role arn:aws:iam::123456789012:role/glue-role \\\n",
    "    --database-name my-database \\\n",
    "    --targets '{\"s3Targets\": [{\"path\": \"s3://your-s3-bucket/\"}]}' \\\n",
    "    --table-prefix my_prefix_ \\\n",
    "    --schema-change-policy '{\"UpdateBehavior\": \"UPDATE_IN_DATABASE\", \"DeleteBehavior\": \"DELETE_FROM_DATABASE\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws glue start-crawler --name my-glue-crawler\n",
    "aws glue get-crawler --name my-glue-crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REATE EXTERNAL SCHEMA my_extern_schema\n",
    "FROM DATA CATALOG\n",
    "DATABASE 'my-database'\n",
    "IAM_ROLE 'arn:aws:iam::123456789012:role/redshift-role'\n",
    "CREATE EXTERNAL DATABASE IF NOT EXISTS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM my_extern_schema.my_prefix_my_table\n",
    "WHERE column_name = 'some_value';"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
